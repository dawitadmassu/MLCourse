{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMpWWIIKoiE5XfBHiPrB3t8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanadv/MLCourse/blob/main/Classification_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o1vLrqoGSJFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "\n",
        "#Converting Categorical Variables to Numeric: Many machine learning models, including XGBClassifier, cannot handle categorical variables directly. The code identifies all columns of type 'object' in the DataFrame (assumed to be categorical) and converts them into numeric values using LabelEncoder. This is done by mapping each unique category to a unique integer.\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "#specifying axis=1 refers to the operation being performed along the columns. This contrasts with axis=0, which would mean the operation is performed along the rows.\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = XGBClassifier(use_label_encoder=False)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_train_proba = model.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_val_proba = model.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGQT6-K3wthE",
        "outputId": "7ee17c7b-f34a-4094-8a91-d9d531183173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
            "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.02\n",
            "Training Accuracy: 100.00%\n",
            "Validation Loss: 0.05\n",
            "Validation Accuracy: 99.08%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      1007\n",
            "           1       0.95      0.99      0.97       193\n",
            "\n",
            "    accuracy                           0.99      1200\n",
            "   macro avg       0.98      0.99      0.98      1200\n",
            "weighted avg       0.99      0.99      0.99      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_train_proba = model.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_val_proba = model.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBjc_U7Xq1iE",
        "outputId": "f5b5b704-ba18-45c6-8183-4133cbf1983d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.38\n",
            "Training Accuracy: 85.95%\n",
            "Validation Loss: 0.41\n",
            "Validation Accuracy: 83.92%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      1.00      0.91      1007\n",
            "           1       0.00      0.00      0.00       193\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.42      0.50      0.46      1200\n",
            "weighted avg       0.70      0.84      0.77      1200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from statsmodels.genmod.generalized_linear_model import GLM\n",
        "from statsmodels.genmod.families import Binomial\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "import numpy as np\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = GLM(y_train, X_train, family=Binomial())\n",
        "result = model.fit()\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = result.predict(X_train)\n",
        "y_pred_train_proba = np.column_stack((1-y_pred_train, y_pred_train))\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train.round())\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = result.predict(X_val)\n",
        "y_pred_val_proba = np.column_stack((1-y_pred_val, y_pred_val))\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val.round())\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val.round()))\n"
      ],
      "metadata": {
        "id": "0Ya81ciPr9vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bdf2beb-e593-4ab5-a184-3ce5a9a024be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.38\n",
            "Training Accuracy: 85.89%\n",
            "Validation Loss: 0.43\n",
            "Validation Accuracy: 83.92%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      1.00      0.91      1007\n",
            "           1       0.00      0.00      0.00       193\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.42      0.50      0.46      1200\n",
            "weighted avg       0.70      0.84      0.77      1200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model1 = LogisticRegression(max_iter=1000)\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model1.predict(X_train)\n",
        "y_pred_train_proba = model1.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model1.predict(X_val)\n",
        "y_pred_val_proba = model1.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val.round()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBLYU0VzsAk8",
        "outputId": "774a75de-66cf-435c-9c2e-dadf227b71fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.39\n",
            "Training Accuracy: 85.95%\n",
            "Validation Loss: 0.43\n",
            "Validation Accuracy: 83.92%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      1.00      0.91      1007\n",
            "           1       0.00      0.00      0.00       193\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.42      0.50      0.46      1200\n",
            "weighted avg       0.70      0.84      0.77      1200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_train_proba = model.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_val_proba = model.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Display first 10 actual vs. predicted responses from the test set\n",
        "first_10_actual = y_test[:10]\n",
        "first_10_predicted = y_pred_test[:10]\n",
        "\n",
        "print(\"First 10 Actual Responses: \", first_10_actual.values)\n",
        "print(\"First 10 Predicted Responses: \", first_10_predicted)\n",
        "\n",
        "# Optionally, you could display them side by side for easier comparison\n",
        "for actual, predicted in zip(first_10_actual, first_10_predicted):\n",
        "    print(f\"Actual: {actual}, Predicted: {predicted}\")\n"
      ],
      "metadata": {
        "id": "mTBD2tSAslK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7ac767-03d0-4b4c-b1ac-22ce15ad87b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.00\n",
            "Training Accuracy: 100.00%\n",
            "Validation Loss: 1.71\n",
            "Validation Accuracy: 95.25%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97      1007\n",
            "           1       0.78      0.98      0.87       193\n",
            "\n",
            "    accuracy                           0.95      1200\n",
            "   macro avg       0.89      0.96      0.92      1200\n",
            "weighted avg       0.96      0.95      0.95      1200\n",
            "\n",
            "First 10 Actual Responses:  [0 0 0 0 1 0 0 1 0 1]\n",
            "First 10 Predicted Responses:  [0 0 1 0 1 0 0 1 0 1]\n",
            "Actual: 0, Predicted: 0\n",
            "Actual: 0, Predicted: 0\n",
            "Actual: 0, Predicted: 1\n",
            "Actual: 0, Predicted: 0\n",
            "Actual: 1, Predicted: 1\n",
            "Actual: 0, Predicted: 0\n",
            "Actual: 0, Predicted: 0\n",
            "Actual: 1, Predicted: 1\n",
            "Actual: 0, Predicted: 0\n",
            "Actual: 1, Predicted: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_train_proba = model.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_val_proba = model.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkh-P5o8ZjMs",
        "outputId": "791f42da-8de4-40a3-8efb-e83a569939a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.04\n",
            "Training Accuracy: 100.00%\n",
            "Validation Loss: 0.11\n",
            "Validation Accuracy: 99.33%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      1007\n",
            "           1       0.99      0.97      0.98       193\n",
            "\n",
            "    accuracy                           0.99      1200\n",
            "   macro avg       0.99      0.98      0.99      1200\n",
            "weighted avg       0.99      0.99      0.99      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
        "model.add(Dense(16, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "_, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_acc * 100.0))\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_acc * 100.0))\n",
        "\n",
        "# Predict classes\n",
        "# Predict probabilities\n",
        "y_pred_val_probs = model.predict(X_val)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred_val = (y_pred_val_probs > 0.5).astype(int).reshape(-1)\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWlcdGmwY1WD",
        "outputId": "9d6944f8-6306-4033-b6d9-c137eabbf3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "175/175 [==============================] - 6s 4ms/step - loss: 0.4399 - accuracy: 0.8270 - val_loss: 0.4244 - val_accuracy: 0.8392\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3694 - accuracy: 0.8591 - val_loss: 0.4118 - val_accuracy: 0.8383\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8584 - val_loss: 0.4093 - val_accuracy: 0.8383\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.8593 - val_loss: 0.3984 - val_accuracy: 0.8375\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8623 - val_loss: 0.3904 - val_accuracy: 0.8375\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8646 - val_loss: 0.3844 - val_accuracy: 0.8350\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3148 - accuracy: 0.8675 - val_loss: 0.3814 - val_accuracy: 0.8400\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8691 - val_loss: 0.3660 - val_accuracy: 0.8383\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 1s 3ms/step - loss: 0.2961 - accuracy: 0.8707 - val_loss: 0.3669 - val_accuracy: 0.8400\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8750 - val_loss: 0.3524 - val_accuracy: 0.8417\n",
            "Training Accuracy: 88.30%\n",
            "Validation Accuracy: 84.17%\n",
            "38/38 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.91      1007\n",
            "           1       0.53      0.14      0.22       193\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.69      0.56      0.57      1200\n",
            "weighted avg       0.80      0.84      0.80      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_train_proba = model.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_val_proba = model.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu2mBj7wmcKM",
        "outputId": "08fc4754-cc6f-4bb1-8daf-89b7132eb70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.24\n",
            "Training Accuracy: 88.16%\n",
            "Validation Loss: 1.35\n",
            "Validation Accuracy: 83.58%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91      1007\n",
            "           1       0.47      0.18      0.26       193\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.67      0.57      0.58      1200\n",
            "weighted avg       0.80      0.84      0.80      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = LinearDiscriminantAnalysis()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_train_proba = model.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_val_proba = model.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scdeeIbqo7T9",
        "outputId": "9a8d06f0-be70-4c8b-b998-bfcf7d642191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.38\n",
            "Training Accuracy: 85.91%\n",
            "Validation Loss: 0.43\n",
            "Validation Accuracy: 83.92%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      1.00      0.91      1007\n",
            "           1       0.00      0.00      0.00       193\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.42      0.50      0.46      1200\n",
            "weighted avg       0.70      0.84      0.77      1200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = QuadraticDiscriminantAnalysis()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_train_proba = model.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_val_proba = model.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILQsP3nnzWhC",
        "outputId": "8c1ffed2-98f8-42b2-869d-2dfa3a21dd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.31\n",
            "Training Accuracy: 86.75%\n",
            "Validation Loss: 0.37\n",
            "Validation Accuracy: 83.67%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.91      1007\n",
            "           1       0.49      0.28      0.36       193\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.68      0.61      0.63      1200\n",
            "weighted avg       0.81      0.84      0.82      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier  # changed from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = GaussianProcessClassifier()  # changed from DecisionTreeClassifier(max_depth=1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_train_proba = model.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_val_proba = model.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn5x9JpK6IMh",
        "outputId": "ad18899f-5a7d-4fb6-8d82-ce8d68b132bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.54\n",
            "Training Accuracy: 100.00%\n",
            "Validation Loss: 0.69\n",
            "Validation Accuracy: 84.33%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      1.00      0.91      1007\n",
            "           1       1.00      0.03      0.05       193\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.92      0.51      0.48      1200\n",
            "weighted avg       0.87      0.84      0.78      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier  # changed from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('ds3.csv')\n",
        "\n",
        "# Convert categorical variables to numeric variables\n",
        "le = LabelEncoder()\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and fit the model on the training set\n",
        "model = AdaBoostClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set and calculate loss\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_train_proba = model.predict_proba(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "train_loss = log_loss(y_train, y_pred_train_proba)\n",
        "\n",
        "# Make predictions on the validation set and calculate loss\n",
        "y_pred_val = model.predict(X_val)\n",
        "y_pred_val_proba = model.predict_proba(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "val_loss = log_loss(y_val, y_pred_val_proba)\n",
        "\n",
        "# Print training and validation loss and accuracy\n",
        "print(\"Training Loss: %.2f\" % train_loss)\n",
        "print(\"Training Accuracy: %.2f%%\" % (train_accuracy * 100.0))\n",
        "print(\"Validation Loss: %.2f\" % val_loss)\n",
        "print(\"Validation Accuracy: %.2f%%\" % (val_accuracy * 100.0))\n",
        "\n",
        "# Print precision, recall, and F1 score for the validation set\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jYgP51Rr2Hu",
        "outputId": "e4c2e2e6-f140-465a-9042-3ffb809e87a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.63\n",
            "Training Accuracy: 87.29%\n",
            "Validation Loss: 0.64\n",
            "Validation Accuracy: 84.83%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92      1007\n",
            "           1       0.63      0.14      0.23       193\n",
            "\n",
            "    accuracy                           0.85      1200\n",
            "   macro avg       0.74      0.56      0.57      1200\n",
            "weighted avg       0.82      0.85      0.81      1200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}